{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import agent\n",
    "import env\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('tensorflow-vgg/')\n",
    "import vgg16\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "data_dir = '/home/vagrant/ocm/language-learning/data'\n",
    "\n",
    "os.chdir('/home/vagrant/ocm/language-learning/code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "logs_path = os.path.join('..','logs')\n",
    "\n",
    "writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "print(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    # load image\n",
    "    img = skimage.io.imread(path)\n",
    "    img = img / 255.0\n",
    "    assert (0 <= img).all() and (img <= 1.0).all()\n",
    "    # print \"Original Image Shape: \", img.shape\n",
    "    # we crop image from center\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    # resize to 224, 224\n",
    "    resized_img = skimage.transform.resize(crop_img, (224, 224))\n",
    "    return resized_img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vagrant/ocm/language-learning/code'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sender.show_images(target, distractor)\n",
    "\n",
    "iterations = 1000\n",
    "\n",
    "img_dirs = ['cat', 'dog']\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_image_activations(sess, vgg, image, placeholder):\n",
    "    #image_pl = tf.placeholder(\"float32\", [1, 224, 224, 3])\n",
    "    batch = image.reshape((1, 224, 224, 3))\n",
    "    feed_dict = {placeholder: batch}\n",
    "    \n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        fc8 = sess.run(vgg.fc8, feed_dict=feed_dict)\n",
    "    \n",
    "    return(fc8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(estimator, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n",
    "\n",
    "    Args:\n",
    "        estimator: An estimator that returns q values for a given state\n",
    "        nA: Number of actions in the environment.\n",
    "\n",
    "    Returns:\n",
    "        A function that takes the (sess, observation, epsilon) as an argument and returns\n",
    "        the probabilities for each action in the form of a numpy array of length nA.\n",
    "\n",
    "    \"\"\"\n",
    "    def policy_fn(sess, observation, epsilon):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        q_values = estimator.predict(sess, np.expand_dims(observation, 0))[0]\n",
    "        best_action = np.argmax(q_values)\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle_image_activations(im_acts):\n",
    "    reordering = np.array(range(len(im_acts)))    \n",
    "    random.shuffle(reordering)\n",
    "    target_ind = np.argmin(reordering)\n",
    "    shuffled = im_acts[reordering]\n",
    "    return (shuffled, target_ind)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W0', 'W1']\n"
     ]
    }
   ],
   "source": [
    "num_words = 2\n",
    "vocab = ['W'+str(i) for i in range(num_words)]\n",
    "\n",
    "#vocab = ['Catword', 'Dogword']\n",
    "embed_dim = 2\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now building the learning graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished building the learning graph\n",
      "build model finished: 0s\n",
      "Episode 0/20000last 10 interations performance  0\n",
      "word probs [ 0.50539732  0.49460265]\n",
      "image probs [ 0.50001913  0.49998084]\n",
      "cat 1.0\n",
      "Episode 1/20000word probs [ 0.50980204  0.49019796]\n",
      "image probs [ 0.50000834  0.49999163]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 0]\n",
      "cat 1.0\n",
      "Episode 2/20000word probs [ 0.77792257  0.22207746]\n",
      "image probs [ 0.50024748  0.49975258]\n",
      "cat 1.0\n",
      "Episode 3/20000word probs [ 0.77792257  0.22207746]\n",
      "image probs [ 0.50603783  0.49396223]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "cat -1.0\n",
      "Episode 4/20000word probs [ 0.87972766  0.12027232]\n",
      "image probs [ 0.49304616  0.50695378]\n",
      "cat -1.0\n",
      "Episode 5/20000word probs [ 0.87972766  0.12027232]\n",
      "image probs [ 0.50658697  0.49341297]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "cat 1.0\n",
      "Episode 6/20000word probs [ 0.92817426  0.0718257 ]\n",
      "image probs [ 0.50286019  0.49713984]\n",
      "cat -1.0\n",
      "Episode 7/20000word probs [ 0.92817426  0.0718257 ]\n",
      "image probs [ 0.5151549   0.48484516]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "cat -1.0\n",
      "Episode 8/20000word probs [ 0.92177612  0.07822389]\n",
      "image probs [ 0.47628063  0.52371937]\n",
      "cat 1.0\n",
      "Episode 9/20000word probs [ 0.92177612  0.07822389]\n",
      "image probs [ 0.51066238  0.48933762]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "cat -1.0\n",
      "Episode 10/20000last 10 interations performance  0.0\n",
      "word probs [ 0.9159658   0.08403419]\n",
      "image probs [ 0.45177907  0.54822099]\n",
      "cat 1.0\n",
      "Episode 11/20000word probs [ 0.9159658   0.08403419]\n",
      "image probs [ 0.50728476  0.49271527]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "dog 1.0\n",
      "Episode 12/20000word probs [ 0.8744598   0.12554021]\n",
      "image probs [ 0.49272665  0.50727338]\n",
      "cat -1.0\n",
      "Episode 13/20000word probs [ 0.8744598   0.12554021]\n",
      "image probs [ 0.54053664  0.45946327]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "dog -1.0\n",
      "Episode 14/20000word probs [ 0.87850207  0.12149794]\n",
      "image probs [ 0.56031924  0.43968078]\n",
      "cat 1.0\n",
      "Episode 15/20000word probs [ 0.87850207  0.12149794]\n",
      "image probs [ 0.42281106  0.57718885]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "cat 1.0\n",
      "Episode 16/20000word probs [ 0.8924768  0.1075232]\n",
      "image probs [ 0.59338516  0.40661481]\n",
      "cat 1.0\n",
      "Episode 17/20000word probs [ 0.8924768  0.1075232]\n",
      "image probs [ 0.47750944  0.52249056]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "cat 1.0\n",
      "Episode 18/20000word probs [ 0.91115403  0.08884596]\n",
      "image probs [ 0.56526846  0.43473151]\n",
      "cat 1.0\n",
      "Episode 19/20000word probs [ 0.91115403  0.08884596]\n",
      "image probs [ 0.51925957  0.48074043]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "dog -1.0\n",
      "Episode 20/20000last 10 interations performance  4.0\n",
      "word probs [ 0.92529595  0.07470403]\n",
      "image probs [ 0.52744395  0.47255599]\n",
      "cat 1.0\n",
      "Episode 21/20000word probs [ 0.92529595  0.07470403]\n",
      "image probs [ 0.44629201  0.55370796]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 0]\n",
      "dog -1.0\n",
      "Episode 22/20000word probs [ 0.93618083  0.0638192 ]\n",
      "image probs [ 0.48288071  0.51711929]\n",
      "cat 1.0\n",
      "Episode 23/20000word probs [ 0.93618083  0.0638192 ]\n",
      "image probs [ 0.49475044  0.50524962]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "cat -1.0\n",
      "Episode 24/20000word probs [ 0.94468808  0.05531198]\n",
      "image probs [ 0.4787856   0.52121431]\n",
      "cat 1.0\n",
      "Episode 25/20000word probs [ 0.94468808  0.05531198]\n",
      "image probs [ 0.52007926  0.47992074]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "dog 1.0\n",
      "Episode 26/20000word probs [ 0.93391305  0.06608697]\n",
      "image probs [ 0.55570531  0.44429466]\n",
      "dog 1.0\n",
      "Episode 27/20000word probs [ 0.93391305  0.06608697]\n",
      "image probs [ 0.5260995  0.4739005]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "cat 1.0\n",
      "Episode 28/20000word probs [ 0.92573011  0.07426988]\n",
      "image probs [ 0.54653317  0.45346683]\n",
      "cat 1.0\n",
      "Episode 29/20000word probs [ 0.92573011  0.07426988]\n",
      "image probs [ 0.48339915  0.51660085]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "cat 1.0\n",
      "Episode 30/20000last 10 interations performance  6.0\n",
      "word probs [ 0.92131925  0.07868078]\n",
      "image probs [ 0.55546719  0.44453281]\n",
      "dog 1.0\n",
      "Episode 31/20000word probs [ 0.92131925  0.07868078]\n",
      "image probs [ 0.54082555  0.45917442]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "dog -1.0\n",
      "Episode 32/20000word probs [ 0.91711622  0.08288381]\n",
      "image probs [ 0.47391686  0.52608317]\n",
      "cat 1.0\n",
      "Episode 33/20000word probs [ 0.91711622  0.08288381]\n",
      "image probs [ 0.54624188  0.45375806]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "dog 1.0\n",
      "Episode 34/20000word probs [ 0.91756684  0.08243313]\n",
      "image probs [ 0.47216472  0.52783525]\n",
      "cat 1.0\n",
      "Episode 35/20000word probs [ 0.91756684  0.08243313]\n",
      "image probs [ 0.48995817  0.51004183]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "dog -1.0\n",
      "Episode 36/20000word probs [ 0.91797417  0.0820258 ]\n",
      "image probs [ 0.48187894  0.51812106]\n",
      "cat 1.0\n",
      "Episode 37/20000word probs [ 0.91797417  0.0820258 ]\n",
      "image probs [ 0.45539063  0.54460943]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "dog 1.0\n",
      "Episode 38/20000word probs [ 0.92252767  0.07747234]\n",
      "image probs [ 0.46207353  0.53792644]\n",
      "cat 1.0\n",
      "Episode 39/20000word probs [ 0.92252767  0.07747234]\n",
      "image probs [ 0.52505863  0.47494128]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "dog 1.0\n",
      "Episode 40/20000last 10 interations performance  6.0\n",
      "word probs [ 0.90593386  0.09406612]\n",
      "image probs [ 0.50339794  0.49660212]\n",
      "cat 1.0\n",
      "Episode 41/20000word probs [ 0.90593386  0.09406612]\n",
      "image probs [ 0.45839056  0.54160947]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "cat 1.0\n",
      "Episode 42/20000word probs [ 0.89393908  0.10606094]\n",
      "image probs [ 0.50862592  0.49137402]\n",
      "dog 1.0\n",
      "Episode 43/20000word probs [ 0.89393908  0.10606094]\n",
      "image probs [ 0.52803028  0.47196972]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "cat 1.0\n",
      "Episode 44/20000word probs [ 0.88870251  0.11129749]\n",
      "image probs [ 0.50161505  0.49838489]\n",
      "dog 1.0\n",
      "Episode 45/20000word probs [ 0.88870251  0.11129749]\n",
      "image probs [ 0.48187986  0.51812011]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "cat 1.0\n",
      "Episode 46/20000word probs [ 0.89077991  0.10922013]\n",
      "image probs [ 0.48946273  0.51053733]\n",
      "dog -1.0\n",
      "Episode 47/20000word probs [ 0.89077991  0.10922013]\n",
      "image probs [ 0.51295835  0.48704165]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "cat 1.0\n",
      "Episode 48/20000word probs [ 0.89264202  0.10735793]\n",
      "image probs [ 0.51393282  0.48606724]\n",
      "cat 1.0\n",
      "Episode 49/20000word probs [ 0.89264202  0.10735793]\n",
      "image probs [ 0.51158607  0.48841387]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "dog -1.0\n",
      "Episode 50/20000last 10 interations performance  6.0\n",
      "word probs [ 0.89431399  0.10568602]\n",
      "image probs [ 0.47778085  0.52221912]\n",
      "cat 1.0\n",
      "Episode 51/20000word probs [ 0.89431399  0.10568602]\n",
      "image probs [ 0.5050714   0.49492854]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "dog -1.0\n",
      "Episode 52/20000word probs [ 0.89581704  0.10418292]\n",
      "image probs [ 0.49975145  0.50024855]\n",
      "cat 1.0\n",
      "Episode 53/20000word probs [ 0.89581704  0.10418292]\n",
      "image probs [ 0.50958776  0.49041224]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "dog -1.0\n",
      "Episode 54/20000word probs [ 0.89717001  0.10282993]\n",
      "image probs [ 0.5714618   0.42853823]\n",
      "cat 1.0\n",
      "Episode 55/20000word probs [ 0.89717001  0.10282993]\n",
      "image probs [ 0.48056608  0.51943392]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 0]\n",
      "dog -1.0\n",
      "Episode 56/20000word probs [ 0.89838922  0.10161077]\n",
      "image probs [ 0.54809844  0.45190161]\n",
      "cat -1.0\n",
      "Episode 57/20000word probs [ 0.89838922  0.10161077]\n",
      "image probs [ 0.46199873  0.53800124]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "dog -1.0\n",
      "Episode 58/20000word probs [ 0.91964501  0.08035506]\n",
      "image probs [ 0.49268523  0.50731474]\n",
      "dog 1.0\n",
      "Episode 59/20000word probs [ 0.91964501  0.08035506]\n",
      "image probs [ 0.42464063  0.5753594 ]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "dog 1.0\n",
      "Episode 60/20000last 10 interations performance  0.0\n",
      "word probs [ 0.93832201  0.06167805]\n",
      "image probs [ 0.46617818  0.53382182]\n",
      "dog 1.0\n",
      "Episode 61/20000word probs [ 0.93832201  0.06167805]\n",
      "image probs [ 0.43226284  0.56773722]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "cat 1.0\n",
      "Episode 62/20000word probs [ 0.95346814  0.04653187]\n",
      "image probs [ 0.49890414  0.50109589]\n",
      "dog -1.0\n",
      "Episode 63/20000word probs [ 0.95346814  0.04653187]\n",
      "image probs [ 0.54010963  0.45989037]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "dog 1.0\n",
      "Episode 64/20000word probs [ 0.96412814  0.03587182]\n",
      "image probs [ 0.5034954   0.49650463]\n",
      "cat 1.0\n",
      "Episode 65/20000word probs [ 0.96412814  0.03587182]\n",
      "image probs [ 0.51207656  0.48792347]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "dog 1.0\n",
      "Episode 66/20000word probs [ 0.97238696  0.02761305]\n",
      "image probs [ 0.40772834  0.59227169]\n",
      "dog 1.0\n",
      "Episode 67/20000word probs [ 0.97238696  0.02761305]\n",
      "image probs [ 0.51548308  0.48451686]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "cat -1.0\n",
      "Episode 68/20000word probs [ 0.97828019  0.02171976]\n",
      "image probs [ 0.52734107  0.47265902]\n",
      "cat -1.0\n",
      "Episode 69/20000word probs [ 0.97828019  0.02171976]\n",
      "image probs [ 0.44354245  0.55645758]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "cat 1.0\n",
      "Episode 70/20000last 10 interations performance  4.0\n",
      "word probs [ 0.98256552  0.01743443]\n",
      "image probs [ 0.4444254  0.5555746]\n",
      "dog 1.0\n",
      "Episode 71/20000word probs [ 0.98256552  0.01743443]\n",
      "image probs [ 0.49325094  0.50674903]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "dog -1.0\n",
      "Episode 72/20000word probs [ 0.98573875  0.01426131]\n",
      "image probs [ 0.43618205  0.56381798]\n",
      "dog -1.0\n",
      "Episode 73/20000word probs [ 0.98573875  0.01426131]\n",
      "image probs [ 0.48811972  0.51188022]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "cat 1.0\n",
      "Episode 74/20000word probs [ 0.98812884  0.01187115]\n",
      "image probs [ 0.4804391   0.51956099]\n",
      "dog -1.0\n",
      "Episode 75/20000word probs [ 0.98812884  0.01187115]\n",
      "image probs [ 0.49093375  0.50906628]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "dog -1.0\n",
      "Episode 76/20000word probs [ 0.98987693  0.01012314]\n",
      "image probs [ 0.53446501  0.46553501]\n",
      "dog 1.0\n",
      "Episode 77/20000word probs [ 0.98987693  0.01012314]\n",
      "image probs [ 0.52996522  0.47003478]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 0]\n",
      "dog 1.0\n",
      "Episode 78/20000word probs [ 0.99130589  0.00869405]\n",
      "image probs [ 0.44182333  0.5581767 ]\n",
      "dog 1.0\n",
      "Episode 79/20000word probs [ 0.99130589  0.00869405]\n",
      "image probs [ 0.42916292  0.57083708]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "cat -1.0\n",
      "Episode 80/20000last 10 interations performance  0.0\n",
      "word probs [ 0.99243188  0.00756814]\n",
      "image probs [ 0.41125375  0.58874619]\n",
      "cat 1.0\n",
      "Episode 81/20000word probs [ 0.99243188  0.00756814]\n",
      "image probs [ 0.43703797  0.562962  ]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "dog -1.0\n",
      "Episode 82/20000word probs [ 0.99333006  0.00666989]\n",
      "image probs [ 0.4370349  0.5629651]\n",
      "cat 1.0\n",
      "Episode 83/20000word probs [ 0.99333006  0.00666989]\n",
      "image probs [ 0.51018608  0.48981389]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 1]\n",
      "cat -1.0\n",
      "Episode 84/20000word probs [ 0.99405503  0.00594498]\n",
      "image probs [ 0.43072867  0.56927133]\n",
      "dog 1.0\n",
      "Episode 85/20000word probs [ 0.99405503  0.00594498]\n",
      "image probs [ 0.58757001  0.41242993]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "dog 1.0\n",
      "Episode 86/20000word probs [ 0.99466914  0.00533088]\n",
      "image probs [ 0.66802895  0.33197105]\n",
      "dog 1.0\n",
      "Episode 87/20000word probs [ 0.99466914  0.00533088]\n",
      "image probs [ 0.2128171   0.78718287]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 0]\n",
      "cat -1.0\n",
      "Episode 88/20000word probs [ 0.9951728   0.00482727]\n",
      "image probs [ 0.30041146  0.69958854]\n",
      "dog 1.0\n",
      "Episode 89/20000word probs [ 0.9951728   0.00482727]\n",
      "image probs [ 0.33940747  0.6605925 ]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "cat 1.0\n",
      "Episode 90/20000last 10 interations performance  4.0\n",
      "word probs [ 0.99560517  0.00439481]\n",
      "image probs [ 0.34515426  0.65484571]\n",
      "dog -1.0\n",
      "Episode 91/20000word probs [ 0.99560517  0.00439481]\n",
      "image probs [ 0.53973842  0.46026155]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "cat 1.0\n",
      "Episode 92/20000word probs [ 0.99596488  0.00403513]\n",
      "image probs [ 0.6331166   0.36688343]\n",
      "dog 1.0\n",
      "Episode 93/20000word probs [ 0.99596488  0.00403513]\n",
      "image probs [ 0.39221725  0.60778278]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 0]\n",
      "cat -1.0\n",
      "Episode 94/20000word probs [ 0.99626642  0.00373362]\n",
      "image probs [ 0.65190417  0.34809583]\n",
      "dog -1.0\n",
      "Episode 95/20000word probs [ 0.99626642  0.00373362]\n",
      "image probs [ 0.45242754  0.54757249]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [0 0]\n",
      "cat -1.0\n",
      "Episode 96/20000word probs [ 0.99651104  0.00348895]\n",
      "image probs [ 0.48619014  0.5138098 ]\n",
      "dog -1.0\n",
      "Episode 97/20000word probs [ 0.99651104  0.00348895]\n",
      "image probs [ 0.65295368  0.34704635]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "dog -1.0\n",
      "Episode 98/20000word probs [ 0.99671078  0.00328925]\n",
      "image probs [ 0.50328255  0.49671739]\n",
      "cat 1.0\n",
      "Episode 99/20000word probs [ 0.99671078  0.00328925]\n",
      "image probs [ 0.56534314  0.4346568 ]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "dog -1.0\n",
      "Episode 100/20000last 10 interations performance  -4.0\n",
      "word probs [ 0.99688232  0.00311766]\n",
      "image probs [ 0.37586865  0.62413138]\n",
      "dog 1.0\n",
      "Episode 101/20000word probs [ 0.99688232  0.00311766]\n",
      "image probs [ 0.60851538  0.39148459]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 0]\n",
      "dog 1.0\n",
      "Episode 102/20000word probs [ 0.99703777  0.00296223]\n",
      "image probs [ 0.40568441  0.59431559]\n",
      "dog 1.0\n",
      "Episode 103/20000word probs [ 0.99703777  0.00296223]\n",
      "image probs [ 0.63651574  0.36348426]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "cat -1.0\n",
      "Episode 104/20000word probs [ 0.9971723   0.00282773]\n",
      "image probs [ 0.28617853  0.71382141]\n",
      "dog -1.0\n",
      "Episode 105/20000word probs [ 0.9971723   0.00282773]\n",
      "image probs [ 0.26634359  0.73365641]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "dog 1.0\n",
      "Episode 106/20000word probs [ 0.99728918  0.00271082]\n",
      "image probs [ 0.65020096  0.34979907]\n",
      "cat 1.0\n",
      "Episode 107/20000word probs [ 0.99728918  0.00271082]\n",
      "image probs [ 0.66402429  0.33597571]\n",
      "updating the agent weights\n",
      "This is the target_acts shape:  (2, 1000)\n",
      "The target batch contains these:  [1 1]\n",
      "cat 1.0\n",
      "Episode 108/20000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e78414f5bfc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtarget_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_pl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mdistractor_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistractor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_pl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mreordering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-08291c107367>\u001b[0m in \u001b[0;36mget_image_activations\u001b[0;34m(sess, vgg, image, placeholder)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content_vgg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mfc8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "agents = agent.Agents(vocab, image_embedding_dim = 10, embedding_dim = 10, temperature=10)\n",
    "game = env.Environment(data_dir, img_dirs, 2)\n",
    "\n",
    "## Run the iterations of the game\n",
    "iterations = 20000\n",
    "mini_batch_size = \n",
    "\n",
    "num_classes = len(img_dirs)\n",
    "\n",
    "wins = 0\n",
    "losses = 0\n",
    "\n",
    "update_estimators_every = 50\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=(tf.GPUOptions(per_process_gpu_memory_fraction=0.7)))) as sess:\n",
    "    vgg = vgg16.Vgg16()\n",
    "    \n",
    "    image_pl = tf.placeholder(\"float32\", [1, 224, 224, 3])\n",
    "    vgg.build(image_pl)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    batch = []\n",
    "    Game = namedtuple(\"Game\", [\"im_acts\", \"target_acts\", \"distractor_acts\", \"target\", \"word\", \"selection\", \"reward\"])\n",
    "    tot_reward = 0\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        print(\"\\rEpisode {}/{}\".format(i, iterations), end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('last 10 interations performance ', tot_reward)\n",
    "            tot_reward = 0\n",
    "                    \n",
    "        target_image, distractor_image = game.get_images()\n",
    "        target_class = game.target_class\n",
    "        target_acts = get_image_activations(sess, vgg, target_image, image_pl)\n",
    "        distractor_acts = get_image_activations(sess, vgg, distractor_image, image_pl)\n",
    "        \n",
    "        reordering = np.array([0,1])\n",
    "        random.shuffle(reordering)\n",
    "        target = np.where(reordering==0)[0]\n",
    "        \n",
    "        img_array = [target_acts, distractor_acts] \n",
    "        i1, i2 = [img_array[reordering[i]] for i, img in enumerate(img_array)]\n",
    "\n",
    "        shuffled_acts = np.concatenate([i1, i2], axis=1)\n",
    "        \n",
    "        ## for Sender - take action in reinforcement learning terms\n",
    "        \n",
    "        reward, word, selection = agents.show_images(sess, shuffled_acts, target_acts, distractor_acts, target, target_class)\n",
    "\n",
    "        batch.append(Game(shuffled_acts, target_acts, distractor_acts, target, word, selection, reward))\n",
    "        \n",
    "        if len(batch) > mini_batch_size:\n",
    "            batch.pop(0)\n",
    "\n",
    "        if (i+1) % mini_batch_size == 0:\n",
    "            print('updating the agent weights')\n",
    "            agents.update(sess, batch)\n",
    "            \n",
    "        #reward, word_text = agents.test_sender(sess, shuffled_acts, target, target_class)\n",
    "        print(target_class, reward)\n",
    "        #reward = agents.test_receiver(sess, shuffled_acts, word, target_ind, target_class)\n",
    "        tot_reward += reward\n",
    "        selection = 0\n",
    "        #agents.call_trial(sess, img_array, target_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
