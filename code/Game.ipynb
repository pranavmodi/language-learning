{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import agent\n",
    "import env\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('tensorflow-vgg/')\n",
    "import vgg16\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "data_dir = '/home/vagrant/ocm/language-learning/data'\n",
    "\n",
    "os.chdir('/home/vagrant/ocm/language-learning/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    # load image\n",
    "    img = skimage.io.imread(path)\n",
    "    img = img / 255.0\n",
    "    assert (0 <= img).all() and (img <= 1.0).all()\n",
    "    # print \"Original Image Shape: \", img.shape\n",
    "    # we crop image from center\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    # resize to 224, 224\n",
    "    resized_img = skimage.transform.resize(crop_img, (224, 224))\n",
    "    return resized_img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vagrant/ocm/language-learning/code'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sender.show_images(target, distractor)\n",
    "\n",
    "iterations = 1000\n",
    "\n",
    "img_dirs = ['cat', 'dog']\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_image_activations(sess, vgg, image, placeholder):\n",
    "    #image_pl = tf.placeholder(\"float32\", [1, 224, 224, 3])\n",
    "    batch = image.reshape((1, 224, 224, 3))\n",
    "    feed_dict = {placeholder: batch}\n",
    "    \n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        fc8 = sess.run(vgg.fc8, feed_dict=feed_dict)\n",
    "    \n",
    "    return(fc8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(estimator, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n",
    "\n",
    "    Args:\n",
    "        estimator: An estimator that returns q values for a given state\n",
    "        nA: Number of actions in the environment.\n",
    "\n",
    "    Returns:\n",
    "        A function that takes the (sess, observation, epsilon) as an argument and returns\n",
    "        the probabilities for each action in the form of a numpy array of length nA.\n",
    "\n",
    "    \"\"\"\n",
    "    def policy_fn(sess, observation, epsilon):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        q_values = estimator.predict(sess, np.expand_dims(observation, 0))[0]\n",
    "        best_action = np.argmax(q_values)\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle_image_activations(im_acts):\n",
    "    reordering = np.array(range(len(im_acts)))    \n",
    "    random.shuffle(reordering)\n",
    "    target_ind = np.argmin(reordering)\n",
    "    shuffled = im_acts[reordering]\n",
    "    return (shuffled, target_ind)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W0', 'W1']\n"
     ]
    }
   ],
   "source": [
    "num_words = 2\n",
    "vocab = ['W'+str(i) for i in range(num_words)]\n",
    "\n",
    "#vocab = ['Catword', 'Dogword']\n",
    "embed_dim = 2\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now building the learning graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished building the learning graph\n",
      "WARNING:tensorflow:From <ipython-input-8-a5f4157fa63e>:7 in <module>.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "../logs\n",
      "/home/vagrant/ocm/language-learning/code/tensorflow-vgg/vgg16.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 0s\n",
      "Episode 0/20000last 10 interations performance  0\n",
      "word probs [ 0.50916994  0.49083012]\n",
      "image probs [ 0.49985591  0.50014406]\n",
      "updating the agent weights\n",
      "cat -1.0\n",
      "Episode 1/20000word probs [ 0.42672589  0.57327414]\n",
      "image probs [ 0.49884048  0.50115949]\n",
      "updating the agent weights\n",
      "cat 1.0\n",
      "Episode 2/20000word probs [ 0.36583692  0.63416302]\n",
      "image probs [ 0.51495576  0.48504427]\n",
      "updating the agent weights\n",
      "cat -1.0\n",
      "Episode 3/20000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a5f4157fa63e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtarget_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistractor_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtarget_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_pl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mdistractor_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistractor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_pl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-08291c107367>\u001b[0m in \u001b[0;36mget_image_activations\u001b[0;34m(sess, vgg, image, placeholder)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content_vgg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mfc8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "agents = agent.Agents(vocab, image_embedding_dim = 10, embedding_dim = 10, temperature=10)\n",
    "game = env.Environment(data_dir, img_dirs, 2)\n",
    "\n",
    "logs_path = os.path.join('..','logs')\n",
    "writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "print(logs_path)\n",
    "\n",
    "## Run the iterations of the game\n",
    "iterations = 20000\n",
    "mini_batch_size = 1\n",
    "\n",
    "num_classes = len(img_dirs)\n",
    "\n",
    "wins = 0\n",
    "losses = 0\n",
    "\n",
    "update_estimators_every = 50\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=(tf.GPUOptions(per_process_gpu_memory_fraction=0.7)))) as sess:\n",
    "    vgg = vgg16.Vgg16()\n",
    "    \n",
    "    image_pl = tf.placeholder(\"float32\", [1, 224, 224, 3])\n",
    "    vgg.build(image_pl)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    batch = []\n",
    "    Game = namedtuple(\"Game\", [\"im_acts\", \"target_acts\", \"distractor_acts\", \"target\", \"word\", \"selection\", \"reward\"])\n",
    "    tot_reward = 0\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        print(\"\\rEpisode {}/{}\".format(i, iterations), end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('last 10 interations performance ', tot_reward)\n",
    "            tot_reward = 0\n",
    "                    \n",
    "        target_image, distractor_image = game.get_images()\n",
    "        target_class = game.target_class\n",
    "        target_acts = get_image_activations(sess, vgg, target_image, image_pl)\n",
    "        distractor_acts = get_image_activations(sess, vgg, distractor_image, image_pl)\n",
    "        \n",
    "        reordering = np.array([0,1])\n",
    "        random.shuffle(reordering)\n",
    "        target = np.where(reordering==0)[0]\n",
    "        \n",
    "        img_array = [target_acts, distractor_acts] \n",
    "        i1, i2 = [img_array[reordering[i]] for i, img in enumerate(img_array)]\n",
    "\n",
    "        shuffled_acts = np.concatenate([i1, i2], axis=1)\n",
    "        \n",
    "        ## for Sender - take action in reinforcement learning terms\n",
    "        \n",
    "        reward, word, selection = agents.show_images(sess, shuffled_acts, target_acts, distractor_acts, target, target_class)\n",
    "\n",
    "        batch.append(Game(shuffled_acts, target_acts, distractor_acts, target, word, selection, reward))\n",
    "        \n",
    "        if len(batch) > mini_batch_size:\n",
    "            batch.pop(0)\n",
    "\n",
    "        if (i+1) % mini_batch_size == 0:\n",
    "            print('updating the agent weights')\n",
    "            agents.update(sess, batch)\n",
    "            \n",
    "        #reward, word_text = agents.test_sender(sess, shuffled_acts, target, target_class)\n",
    "        print(target_class, reward)\n",
    "        #reward = agents.test_receiver(sess, shuffled_acts, word, target_ind, target_class)\n",
    "        tot_reward += reward\n",
    "        selection = 0\n",
    "        #agents.call_trial(sess, img_array, target_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
